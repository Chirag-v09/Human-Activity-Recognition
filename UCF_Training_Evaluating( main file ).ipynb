{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Essential Libraries\n",
    "import os\n",
    "# import cv2\n",
    "import time\n",
    "# import math\n",
    "# import glob\n",
    "# import random\n",
    "# import tensorflow\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Parameters\n",
    "dataset = \"UCF-101/\"                                                            # Dataset Path\n",
    "dataset2 = \"dataset/\"                                                           # Dataset2 Path\n",
    "train_path = \"/kaggle/input/vid-classification-ucf101/UCF/training_set/\"        # Training Path for Kaggle\n",
    "test_path = \"/kaggle/input/vid-classification-ucf101/UCF/testing_set/\"          # Testing Path for Kaggle\n",
    "no_of_frames = 1650                                                             # Number of Frames\n",
    "ch = 4                                                                          # Model Selection Choice\n",
    "epochs = 20                                                                     # Number of epochs\n",
    "batch_size = 32                                                                 # Batch Size\n",
    "n_classes = 101                                                                 # Number of Classes\n",
    "patience = 2                                                                    # Patience for EarlyStopping\n",
    "stime = int(time.time())                                                        # Defining Starting Time\n",
    "categories = os.listdir(dataset)                                                # Name of each Class/Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories.sort()\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining ResNet Architecture\n",
    "# resnet = tensorflow.keras.applications.resnet_v2.ResNet50V2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Base Model\n",
    "if ch == 1:\n",
    "    from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
    "    base_model = ResNet50(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n",
    "elif ch == 2:\n",
    "    from tensorflow.keras.applications.resnet import ResNet101, preprocess_input\n",
    "    base_model = ResNet101(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n",
    "elif ch == 3:\n",
    "    from tensorflow.keras.applications.resnet import ResNet150, preprocess_input\n",
    "    base_model = ResNet150(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n",
    "elif ch == 4:\n",
    "    from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n",
    "    base_model = ResNet50V2(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n",
    "elif ch == 5:\n",
    "    from tensorflow.keras.applications.resnet_v2 import ResNet101V2, preprocess_input\n",
    "    base_model = ResNet101V2(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n",
    "elif ch == 6:\n",
    "    from tensorflow.keras.applications.resnet_v2 import ResNet150V2, preprocess_input\n",
    "    base_model = ResNet150V2(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n",
    "elif ch == 7:\n",
    "    from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "    base_model = MobileNet(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n",
    "elif ch == 8:\n",
    "    from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "    base_model = MobileNetV2(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "# x = Dense(512, activation = 'relu')(x)\n",
    "# x = Dense(256, activation = 'relu')(x)\n",
    "\n",
    "preds = Dense(n_classes, activation = 'softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = base_model.input, outputs = preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing names of each layer\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting each layer as trainable\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setting 1/3 layers as trainable\n",
    "# for layer in model.layers[:65]:\n",
    "#     layer.trainable = False\n",
    "# for layer in model.layers[65:]:\n",
    "#     layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Image Data Generators\n",
    "train_datagenerator = ImageDataGenerator(preprocessing_function = preprocess_input,\n",
    "                                         validation_split = 0.2)\n",
    "\n",
    "test_datagenerator = ImageDataGenerator(preprocessing_function = preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagenerator.flow_from_directory(train_path,\n",
    "                                                          target_size = (224, 224),\n",
    "                                                          color_mode = 'rgb',\n",
    "                                                          batch_size = batch_size,\n",
    "                                                          class_mode = 'categorical',\n",
    "                                                          shuffle = True)\n",
    "\n",
    "validation_generator = train_datagenerator.flow_from_directory(train_path,\n",
    "                                                               target_size = (224, 224),\n",
    "                                                               color_mode = 'rgb',\n",
    "                                                               batch_size = batch_size,\n",
    "                                                               class_mode = 'categorical',\n",
    "                                                               subset = 'validation')\n",
    "\n",
    "test_generator = test_datagenerator.flow_from_directory(test_path,\n",
    "                                                        target_size = (224, 224),\n",
    "                                                        color_mode = 'rgb',\n",
    "                                                        class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator.class_indices)\n",
    "print(validation_generator.class_indices)\n",
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the Model\n",
    "model.compile(optimizer = \"Adam\",\n",
    "              loss = \"categorical_crossentropy\",\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSVLogger\n",
    "filename = \"{}_{}b_{}e\\\\file.csv\".format(stime, batch_size, epochs)\n",
    "csv_log = CSVLogger(filename)\n",
    "\n",
    "# Tensorboard\n",
    "# tensorboard = TensorBoard(log_dir = \"{}_{}b_{}e\\logs\".format(stime, batch_size, epochs))\n",
    "\n",
    "# Defining Model Checkpoint\n",
    "checkpoint_name = \"{}_{}b_{}e\".format(stime, batch_size, epochs)\n",
    "checkpoint_path = checkpoint_name + \"\\cp-{epoch:04d}-{accuracy:.4f}a-{loss:.4f}l-{val_accuracy:.4f}va-{val_loss:.4f}vl.h5\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "modelcheckpoint = ModelCheckpoint(checkpoint_path, save_best_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Model\n",
    "history = model.fit(train_generator,\n",
    "                    validation_data = validation_generator,\n",
    "                    epochs = epochs,\n",
    "                    callbacks = [modelcheckpoint, csv_log])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Graph\n",
    "model_history = pd.DataFrame(history.history)\n",
    "model_history.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Model\n",
    "from tensorflow.keras.models import load_model\n",
    "# model = r\"____h5_file_location.h5_Evaluating___\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Model's Performance\n",
    "history2 = model.evaluate_generator(test_generator)\n",
    "# history2 = model.evaluate(test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
